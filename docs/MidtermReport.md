## **Inverse Kinematics Approximation Using Machine Learning**

### **1. Introduction / Background**

Inverse Kinematics (IK) refers to finding specific angle configurations of a robotic arm’s joints that lead to a given end-effector position. Current approaches make use of numerical solvers, which can be slow and often provide only one solution when there are multiple possibilities. In this project, we aim to estimate IK mapping with supervised and unsupervised machine learning, reducing computational complexity, but still maintaining accuracy up to par with current methods.

Several recent works [1] explore the use of neural networks for IK, showing promising results. Unsupervised learning can also assist in understanding configuration space (the set of all possible positions the robot’s joints can take i.e. Joint 1 can rotate from 0° to 180°, Joint 2 from -90° to 90°, Joint 3 from 0° to 150°) and clustering feasible/optimal joint angle patterns for given tasks.

### **2. Problem Definition**

The IK problem often faces multiple possible joint configurations for a single end position. Our objective is to develop a machine learning model that predicts both a feasible and accurate joint configuration given a target end location in 3D space. This approach enables real-time performance for control systems in robotics, replacing slower iterative solvers that are especially affected by creep and wearing of the arm in the long-run [2].

The IK concept can be extended into unsupervised learning for anomaly detection. A robotic manipulator is considered to be in a “displacement singularity” when its jacobian loses rank. Therefore, unsupervised learning can be used to identify regions of the dataset with an abnormally low manipulability (discussed in Section 5), thus allowing us to identify singularities without training labels.

Project outcomes:

1. Supervised learning model for inverse kinematic approximation/prediction. Given an end-effector position in task-space, we aim to approximate the corresponding angles in joint-space that produce the specified orientation at the end-effector. Later iterations of this model will incorporate manipalibility as a secondary optimization goal.

2. Unsupervised learning model for singularity detection.

### **3. Methods**

**Data Acquisition Methods:**

Our dataset was generated by randomly sampling the joint space of a robotic manipulator with four revolute joints in the configuration shown below.

![Enter image alt description](https://d3gf5wsgt7m4.cloudfront.net/FREE_LICENSE/nkw_Image_1.png)

Figure 1: Robotic Arm Diagram [3]

After randomly sampling for 200,000 joint-space coordinate sets [θ~1~ θ~2 ~θ~3 ~θ~4~], we used forward kinematics to determine the corresponding task-space coordinates [x y z] of the end-effector. We also used random sampling from a gaussian distribution to introduce some noise to the dataset. The primary motivation here was to emulate real-world sensor noise to force the supervised model to learn to cope with some level of irregularities. We had originally intended to use a dedicated physics simulator like PyBullet or MuJoCo, but it turned out that a simpler implementation using random sampling and forward kinematics was sufficient. The raw dataset is a .csv file containing a concatenation of the task-space and joint space columns [x y z θ~1~ θ~2 ~θ~3 ~θ~4~]. A pretreatment module using sklearn.model_selection.train_test_split() allowed us to partition the data with 80% for training, 10% for testing and 10% for validation.

#### **Implemented Preprocessing Methods:**

```
sklearn.preprocessing.StandardScaler

```

Machine learning algorithms work well when the input data are on a similar scale. Hence, we used the `sklearn.preprocessing.StandardScaler` to ensure that our data is centered around the mean and scaled to unit variance. The standardization provided by StandardScaler also helps our training model to converge faster as it prevents the possibility of parameters dominating the objective function and skewing the results. [4]

#### **Implemented Supervised Learning Methods:**

```
sklearn.neural_network.MLPRegressor

```

sklearn.neural_network.MLPRegressor serves as our neural network model and we use it to solve the inverse kinematics (IK) problem where we predict the joint space angles given the end-effector coordinates. It is capable of learning complex non-linear mappings between 3D task-space coordinates and 4D joint-space configurations through multiple hidden layers with backpropagation training. The model utilizes the ‘Adam’ optimizer to adjust the learning rates during training to achieve better efficiency. Also, `StandardScaler` (from the same toolkit) and `MLPRegressor `integrate well together to achieve standardized input data which leads to efficiently converging outputs.[5]

#### **Unsupervised Learning Methods (not yet implemented):**


- Clustering of joint angle configurations using K-Means to group similar poses together (like "elbow up" vs "elbow down")

- Singularity detection:

- Find nearest neighbors for a given point using  `sklearn.neighbors.NearestNeighbors`

- PCA for dimensionality reduction with `sklearn.decomposition.PCA`

- Isolation forest for anomaly detection using `sklearn.ensemble.IsolationForest `

- DBSCAN to cluster singularity scores with `sklearn.cluster.DBSCAN`

### **4. Results and Discussion**


Since our present implementation ignores end-effector orientation and considers only end-effector location, there are infinitely many valid inverse kinematic solutions for a given XYZ coordinate (the manipulator is “kinematically redundant”). Therefore, calculating error metrics based on the predicted angles is not helpful, since there is no single IK solution that we can use as ground truth. Instead, our implementation takes the predicted angles and runs them through the forward kinematics function to determine the XYZ coordinate that the model implies from its predictions for [θ~1~ θ~2 ~θ~3 ~θ~4~]. This transformation from joint-space to task-space gives us the ground truth we need to evaluate the model’s performance. We calculate MSE, RMSE, and R^2^ based on these position values. Our results are as follows:

- Position MSE: 0.008371 m^2^

- Position RMSE: 0.091491 m

- Position R^2^: 0.9544

Figure 2 below shows a subset of the data, demonstrating how the predicted XYZ coordinates compare to the ground truth XYZ corresponding to the predicted joint angles. Each predicted XYZ-coordinate is color matched to its corresponding ground truth.

![Enter image alt description](https://d3gf5wsgt7m4.cloudfront.net/FREE_LICENSE/z2m_Image_2.png)

Figure 2: Error Analysis Plot

These results are good enough for the first implementation of our model, and provide a good basis for the next steps and improvements described in the following section.

### **5. Next Steps**

Currently the model just predicts some IK solution for a given XYZ coordinate, meaning that no importance is assigned to the characteristics of the predicted solution as of the current implementation. The model only optimizes for the accuracy of the solution. Since there is an infinite continuum of IK solutions for any XYZ, the current model is not very helpful. Therefore, we will create a second model that not only optimizes for prediction accuracy, but actually recommends a specific IK solution that optimizes manipulability.

Manipulability refers to the ability of a robotic arm to quickly alter the position of the end-effector from a given joint configuration.

![Enter image alt description](https://d3gf5wsgt7m4.cloudfront.net/FREE_LICENSE/i71_Image_3.png)

Figure 3: Manipulability Example [6]

The ellipsoids shown above in Figure 3 depict a graphical representation of the manipulability metric of a robotic arm. A low manipulability (narrow ellipsoid) corresponds with proximity to a singularity, meaning the robot has reduced range of motion. This is, generally speaking, undesirable. A high manipulability (wide ellipsoid), however, characterizes a posture with a large range of motion. Manipulability can be calculated numerically using roboticstoolbox.jacobe(), which can be ported directly into our training data. Thus, our next model will train not only on prediction accuracy, but will also optimize for manipulability. Furthermore, we will aim to use the unsupervised methods from Section 4 to determine when the robot is in or closeby to a singularity, which closely relates to our manipulability application.

### **6. Gantt Chart and Proposal Contributions**

![Enter image alt description](https://d3gf5wsgt7m4.cloudfront.net/FREE_LICENSE/IIF_Image_4.png)

| Name | Midterm Contributions |
|---|---|
| Yash Tahilliani | Formatted proposal content for GitHub, and handled citations and references. |
| Terry Barrigah | Wrote section on supervised learning methods. |
| Joao Pedro Fonseca | Defined project scope and objectives, drafted introduction and problem statement, and helped plan ML methods. |
| Anand Nagpurkar | Conducted literature review, summarized related work, wrote about supervised learning methods and preprocessing methods. Verified code pipeline. |
| Jackson Merrick | Implemented data acquisition, model training, and evaluation. Contributed to report. |

### **7. References**

[1] F. L. Tagliani, N. Pellegrini, and F. Aggogeri, “Machine learning sequential methodology for robot inverse kinematic modelling,” Applied Sciences, vol. 12, no. 19, p. 9417, Sep. 2022. doi: 10.3390/app12199417

[2] M. N. Vu, F. Beck, M. Schwegel, C. Hartl-Nesic, A. Nguyen, and A. Kugi, “Machine learning-based framework for optimally solving the analytical inverse kinematics for redundant manipulators,” *Mechatronics*, vol. 89, p. 102970, 2023. doi:[10.1016/j.mechatronics.2023.102970](https://doi.org/10.1016/j.mechatronics.2023.102970)

[3][https://www.researchgate.net/figure/BioRob-4-DOF-robot-arm-kinematic-structure-and-table-with-DH-parameters_fig4_220850180](https://www.researchgate.net/figure/BioRob-4-DOF-robot-arm-kinematic-structure-and-table-with-DH-parameters_fig4_220850180)

[4][https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)

[5][https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) 

[6][https://www.roboticsunveiled.com/robotics-velocity-manipulability-force-ellipsoids/](https://www.roboticsunveiled.com/robotics-velocity-manipulability-force-ellipsoids/)

[7] R. F. Reinhart, Z. Shareef, and J. J. Steil, “Hybrid analytical and data-driven modeling for feed-forward robot control,” Sensors, vol. 17, no. 2, p. 311, Feb. 2017. doi: 10.3390/s17020311
